#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°†é›·è¾¾ç‚¹äº‘æŠ•å½±åˆ°å¤šè§†è§’RGBå›¾åƒä¸­ï¼ˆå¸¦é•œåƒä¿®æ­£å’Œåˆšæ€§å˜æ¢å¯¹é½ï¼‰
æ”¯æŒç”Ÿæˆè§†é¢‘è¾“å‡º

ä¿®æ­£å†…å®¹ï¼š
1. é•œåƒä¿®æ­£ï¼šç‚¹äº‘é‡‡é›†æ˜¯é•œåƒçš„ï¼Œéœ€è¦ç¿»è½¬
2. åˆšæ€§å˜æ¢ï¼šé›·è¾¾ç›¸å¯¹äºcam12çš„ä½ç½®åç§»ï¼ˆå·¦13cmï¼Œä¸‹4cmï¼Œå‰3cmï¼‰
"""

import os
import sys
import argparse

sys.path.insert(0, os.path.dirname(__file__))

import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from glob import glob


def load_cameras(intri_path, extri_path, camera_names):
    """åŠ è½½ç›¸æœºå†…å¤–å‚"""
    cameras = {}
    
    intri_fs = cv2.FileStorage(intri_path, cv2.FILE_STORAGE_READ)
    extri_fs = cv2.FileStorage(extri_path, cv2.FILE_STORAGE_READ)
    
    for cam_name in camera_names:
        cameras[cam_name] = {
            'K': intri_fs.getNode(f'K_{cam_name}').mat(),
            'dist': intri_fs.getNode(f'dist_{cam_name}').mat().flatten(),
            'R': extri_fs.getNode(f'Rot_{cam_name}').mat(),
            'T': extri_fs.getNode(f'T_{cam_name}').mat()
        }
    
    intri_fs.release()
    extri_fs.release()
    
    return cameras


def radar_spherical_to_cartesian(range_m, az_deg, el_deg):
    """
    å°†é›·è¾¾çƒåæ ‡è½¬æ¢ä¸ºç¬›å¡å°”åæ ‡ï¼ˆé›·è¾¾åæ ‡ç³»ï¼‰
    é›·è¾¾åæ ‡ç³»: Xå‰, Yå·¦, Zä¸Š
    """
    az_rad = np.deg2rad(az_deg)
    el_rad = np.deg2rad(el_deg)
    
    x = range_m * np.cos(el_rad) * np.cos(az_rad)
    y = range_m * np.cos(el_rad) * np.sin(az_rad)
    z = range_m * np.sin(el_rad)
    
    return np.stack([x, y, z], axis=1)


def transform_radar_to_camera_with_calibration(
    radar_points, 
    translation_offset=None
):
    """
    å°†é›·è¾¾åæ ‡ç³»è½¬æ¢åˆ°ç›¸æœºåæ ‡ç³»ï¼ˆå¸¦åˆšæ€§å˜æ¢ï¼‰
    
    Args:
        radar_points: (N, 3) é›·è¾¾åæ ‡ç³»ç‚¹äº‘ [Xå‰, Yå·¦, Zä¸Š]
        translation_offset: [dx, dy, dz] é›·è¾¾ç›¸å¯¹ç›¸æœºçš„åç§»ï¼ˆç›¸æœºåæ ‡ç³»ï¼‰
                           é»˜è®¤ [-0.13, 0.04, 0.03] è¡¨ç¤ºé›·è¾¾åœ¨ç›¸æœºå·¦13cmã€ä¸‹4cmã€å‰3cm
    
    åæ ‡ç³»è½¬æ¢ï¼š
        é›·è¾¾åæ ‡ç³»: Xå‰, Yå·¦, Zä¸Š
        ç›¸æœºåæ ‡ç³»: Xå³, Yä¸‹, Zå‰
    
    æ­¥éª¤ï¼š
        1. åæ ‡è½´è½¬æ¢ï¼š
           cam_X = -radar_Y (é›·è¾¾å·¦ -> ç›¸æœºå³)
           cam_Y = -radar_Z (é›·è¾¾ä¸Š -> ç›¸æœºä¸‹)
           cam_Z =  radar_X (é›·è¾¾å‰ -> ç›¸æœºå‰)
        2. åˆšæ€§å˜æ¢ï¼šåŠ ä¸Šé›·è¾¾ç›¸å¯¹ç›¸æœºçš„åç§»
    """
    radar_points = radar_points.copy()
    
    # æ­¥éª¤1: åæ ‡è½´è½¬æ¢åˆ°ç›¸æœºåæ ‡ç³»
    cam_points = np.zeros_like(radar_points)
    cam_points[:, 0] = -radar_points[:, 1]  # cam_X = -radar_Y
    cam_points[:, 1] = -radar_points[:, 2]  # cam_Y = -radar_Z
    cam_points[:, 2] = radar_points[:, 0]   # cam_Z = radar_X
    
    # æ­¥éª¤2: åˆšæ€§å˜æ¢ï¼ˆé›·è¾¾ç›¸å¯¹ç›¸æœºçš„åç§»ï¼‰
    if translation_offset is None:
        # é»˜è®¤åç§»ï¼šé›·è¾¾åœ¨ç›¸æœºå·¦13cmã€ä¸‹4cmã€å‰3cm
        # ç›¸æœºåæ ‡ç³»ï¼šXå³æ­£ï¼ŒYä¸‹æ­£ï¼ŒZå‰æ­£
        # é›·è¾¾åœ¨å·¦è¾¹ -> Xè´Ÿï¼Œä¸‹æ–¹ -> Yæ­£ï¼Œå‰æ–¹ -> Zæ­£
        translation_offset = np.array([-0.13, 0.04, 0.03])
    
    cam_points += translation_offset
    
    return cam_points


def project_points(points_3d, K, R, T, dist):
    """å°†3Dç‚¹æŠ•å½±åˆ°2Då›¾åƒå¹³é¢"""
    points_cam = (R @ points_3d.T + T).T
    points_2d = points_cam[:, :2] / points_cam[:, 2:3]
    
    fx, fy = K[0, 0], K[1, 1]
    cx, cy = K[0, 2], K[1, 2]
    
    points_2d[:, 0] = points_2d[:, 0] * fx + cx
    points_2d[:, 1] = points_2d[:, 1] * fy + cy
    
    return points_2d, points_cam[:, 2]


def load_radar_data(csv_path):
    """åŠ è½½é›·è¾¾ç‚¹äº‘æ•°æ®ï¼ˆæ–°è¡¨å¤´æ ¼å¼ï¼‰"""
    df = pd.read_csv(csv_path)
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºæ–°è¡¨å¤´æ ¼å¼
    if 'frame_index' in df.columns:
        # æ–°è¡¨å¤´æ ¼å¼
        df = df.rename(columns={
            'frame_index': 'frame',
            'range': 'range_m',
            'velocity': 'vel_mps',
            'horizontal_angle': 'az_deg',
            'elevation_angle': 'el_deg',
            'power': 'mag'
        })
    elif 'frame' not in df.columns:
        raise ValueError("CSVæ–‡ä»¶ç¼ºå°‘ 'frame' æˆ– 'frame_index' åˆ—")
    
    return df


def load_camera_images(data_root, cam_name):
    """åŠ è½½æŸä¸ªç›¸æœºçš„æ‰€æœ‰jpgå›¾ç‰‡"""
    cam_dir = os.path.join(data_root, 'images', cam_name)
    if not os.path.isdir(cam_dir):
        return [], {}
    images = [
        os.path.join(cam_dir, f)
        for f in sorted(os.listdir(cam_dir))
        if f.lower().endswith('.jpg')
    ]
    name_map = {os.path.splitext(os.path.basename(p))[0]: p for p in images}
    return images, name_map


def choose_image(frame_name, order_idx, images_sorted, name_map):
    """é€‰æ‹©ä¸å¸§å¯¹åº”çš„å›¾åƒ"""
    if frame_name in name_map:
        return name_map[frame_name], "name"
    for name, path in name_map.items():
        if name.endswith(frame_name):
            return path, "suffix"
    if order_idx < len(images_sorted):
        return images_sorted[order_idx], "order"
    return None, "missing"


def draw_pointcloud(img, points_2d, depth, power=None, color_mode='depth', point_size=3):
    """
    åœ¨å›¾åƒä¸Šç»˜åˆ¶ç‚¹äº‘
    color_mode: 'depth' - æŒ‰æ·±åº¦ç€è‰², 'power' - æŒ‰åŠŸç‡ç€è‰², 'fixed' - å›ºå®šé¢œè‰²
    """
    result = img.copy()
    h, w = result.shape[:2]
    
    if len(points_2d) == 0:
        return result
    
    # åªç»˜åˆ¶æ·±åº¦ä¸ºæ­£çš„ç‚¹
    valid_mask = depth > 0
    points_2d = points_2d[valid_mask]
    depth = depth[valid_mask]
    if power is not None:
        power = power[valid_mask]
    
    if len(points_2d) == 0:
        return result
    
    # æ ¹æ®æ¨¡å¼é€‰æ‹©é¢œè‰²
    if color_mode == 'depth':
        # æŒ‰æ·±åº¦ç€è‰²ï¼ˆè¿‘çº¢è¿œè“ï¼‰
        depth_normalized = (depth - depth.min()) / (depth.max() - depth.min() + 1e-6)
        colors = plt.cm.jet(depth_normalized)[:, :3] * 255
        colors = colors.astype(np.uint8)
    elif color_mode == 'power' and power is not None:
        # æŒ‰åŠŸç‡ç€è‰²ï¼ˆä½ç»¿é«˜çº¢ï¼‰
        power_normalized = (power - power.min()) / (power.max() - power.min() + 1e-6)
        colors = plt.cm.hot(power_normalized)[:, :3] * 255
        colors = colors.astype(np.uint8)
    else:
        # å›ºå®šé¢œè‰²ï¼ˆç»¿è‰²ï¼‰
        colors = np.tile([0, 255, 0], (len(points_2d), 1))
    
    # ç»˜åˆ¶ç‚¹
    for (u, v), color in zip(points_2d, colors):
        pt = (int(round(u)), int(round(v)))
        if 0 <= pt[0] < w and 0 <= pt[1] < h:
            color_bgr = tuple(map(int, color[::-1]))  # RGB -> BGR
            cv2.circle(result, pt, point_size, color_bgr, -1, cv2.LINE_AA)
    
    return result


def create_video_from_images(image_dir, output_video_path, fps=10):
    """ä»å›¾åƒåºåˆ—åˆ›å»ºè§†é¢‘"""
    images = sorted([f for f in os.listdir(image_dir) if f.lower().endswith('.jpg')])
    
    if len(images) == 0:
        print(f"   âš ï¸  {image_dir} ä¸­æ²¡æœ‰å›¾åƒ")
        return False
    
    first_img = cv2.imread(os.path.join(image_dir, images[0]))
    if first_img is None:
        return False
    
    h, w = first_img.shape[:2]
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (w, h))
    
    for img_name in tqdm(images, desc=f"ç”Ÿæˆè§†é¢‘ {os.path.basename(output_video_path)}", leave=False):
        img = cv2.imread(os.path.join(image_dir, img_name))
        if img is not None:
            out.write(img)
    
    out.release()
    print(f"   âœ… è§†é¢‘å·²ä¿å­˜: {output_video_path}")
    return True


# å¯¼å…¥matplotlibç”¨äºé¢œè‰²æ˜ å°„
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt


def main():
    parser = argparse.ArgumentParser(description='å°†é›·è¾¾ç‚¹äº‘æŠ•å½±åˆ°å¤šè§†è§’å›¾åƒï¼ˆå¸¦å¯¹é½ä¿®æ­£ï¼‰')
    parser.add_argument('--data_root', type=str, default='../data/examples/my_multiview')
    parser.add_argument('--radar_csv', type=str, required=True,
                        help='é›·è¾¾ç‚¹äº‘CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--cameras', type=str, nargs='+', 
                        default=['cam0', 'cam2', 'cam4', 'cam6', 'cam12'])
    parser.add_argument('--frame_start', type=int, default=0)
    parser.add_argument('--frame_end', type=int, default=99999)
    parser.add_argument('--color_mode', type=str, default='depth',
                        choices=['depth', 'power', 'fixed'],
                        help='ç‚¹äº‘ç€è‰²æ¨¡å¼: depth-æŒ‰æ·±åº¦, power-æŒ‰åŠŸç‡, fixed-å›ºå®šé¢œè‰²')
    parser.add_argument('--point_size', type=int, default=4,
                        help='ç‚¹çš„å¤§å°')
    parser.add_argument('--min_power', type=float, default=0.0,
                        help='æœ€å°åŠŸç‡é˜ˆå€¼ï¼Œè¿‡æ»¤ä½åŠŸç‡ç‚¹')
    parser.add_argument('--max_depth', type=float, default=10.0,
                        help='æœ€å¤§æ·±åº¦ï¼ˆç±³ï¼‰ï¼Œè¿‡æ»¤è¿‡è¿œçš„ç‚¹')
    parser.add_argument('--offset_x', type=float, default=-0.13,
                        help='é›·è¾¾ç›¸å¯¹ç›¸æœºXåç§»ï¼ˆç±³ï¼‰ï¼Œè´Ÿå€¼è¡¨ç¤ºå·¦ä¾§ï¼Œé»˜è®¤-0.13')
    parser.add_argument('--offset_y', type=float, default=0.04,
                        help='é›·è¾¾ç›¸å¯¹ç›¸æœºYåç§»ï¼ˆç±³ï¼‰ï¼Œæ­£å€¼è¡¨ç¤ºä¸‹æ–¹ï¼Œé»˜è®¤0.04')
    parser.add_argument('--offset_z', type=float, default=0.03,
                        help='é›·è¾¾ç›¸å¯¹ç›¸æœºZåç§»ï¼ˆç±³ï¼‰ï¼Œæ­£å€¼è¡¨ç¤ºå‰æ–¹ï¼Œé»˜è®¤0.03')
    parser.add_argument('--create_video', action='store_true')
    parser.add_argument('--video_fps', type=int, default=10,
                        help='è§†é¢‘å¸§ç‡ï¼ˆå»ºè®®ä¸é‡‡é›†å¸§ç‡ä¸€è‡´ï¼Œé»˜è®¤10fpsï¼‰')
    parser.add_argument('--output_dir_name', type=str, default='vis_pointcloud_aligned')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    vis_output_dir = os.path.join(os.path.dirname(args.radar_csv), args.output_dir_name)
    os.makedirs(vis_output_dir, exist_ok=True)
    
    for cam_name in args.cameras:
        os.makedirs(os.path.join(vis_output_dir, cam_name), exist_ok=True)
    
    # åŠ è½½ç›¸æœºå‚æ•°
    print("ğŸ“· åŠ è½½ç›¸æœºå‚æ•°...")
    intri_path = os.path.join(args.data_root, 'intri.yml')
    extri_path = os.path.join(args.data_root, 'extri.yml')
    cameras = load_cameras(intri_path, extri_path, args.cameras)
    print(f"   æ‰¾åˆ° {len(cameras)} ä¸ªç›¸æœº: {args.cameras}")
    
    # åŠ è½½é›·è¾¾æ•°æ®
    print("ğŸ“¡ åŠ è½½é›·è¾¾ç‚¹äº‘æ•°æ®...")
    radar_df = load_radar_data(args.radar_csv)
    print(f"   æ€»ç‚¹æ•°: {len(radar_df)}")
    print(f"   å¸§æ•°: {radar_df['frame'].nunique()}")
    
    # é¢„åŠ è½½æ¯ä¸ªç›¸æœºçš„å›¾ç‰‡åˆ—è¡¨
    cam_images = {cam: load_camera_images(args.data_root, cam) for cam in args.cameras}
    for cam, (imgs, _) in cam_images.items():
        print(f"   ç›¸æœº {cam} å‘ç° {len(imgs)} å¼ å›¾ç‰‡")
    
    # è·å–è¦å¤„ç†çš„å¸§åˆ—è¡¨
    all_frames = sorted(radar_df['frame'].unique())
    frames = [f for f in all_frames if args.frame_start <= f <= args.frame_end]
    
    if len(frames) == 0:
        print("âŒ æœªæ‰¾åˆ°åŒ¹é…çš„å¸§")
        return
    
    print(f"\nâ˜ï¸  å¼€å§‹æŠ•å½±ç‚¹äº‘åˆ°å›¾åƒï¼ˆå¸¦å¯¹é½ä¿®æ­£ï¼‰")
    print(f"   å¸§æ•°: {len(frames)}")
    print(f"   è§†è§’æ•°: {len(args.cameras)}")
    print(f"   ç€è‰²æ¨¡å¼: {args.color_mode}")
    print(f"   ç‚¹å¤§å°: {args.point_size}")
    print(f"   æœ€å°åŠŸç‡: {args.min_power}")
    print(f"   æœ€å¤§æ·±åº¦: {args.max_depth}m")
    print(f"   åˆšæ€§åç§»: X={args.offset_x}m, Y={args.offset_y}m, Z={args.offset_z}m")
    print(f"              (é›·è¾¾åœ¨ç›¸æœº: {'å·¦' if args.offset_x < 0 else 'å³'}{abs(args.offset_x)*100:.0f}cm, "
          f"{'ä¸‹' if args.offset_y > 0 else 'ä¸Š'}{abs(args.offset_y)*100:.0f}cm, "
          f"{'å‰' if args.offset_z > 0 else 'å'}{abs(args.offset_z)*100:.0f}cm)\n")
    
    translation_offset = np.array([args.offset_x, args.offset_y, args.offset_z])
    
    for order_idx, frame_idx in enumerate(tqdm(frames, desc="å¤„ç†è¿›åº¦")):
        # è·å–è¯¥å¸§çš„é›·è¾¾æ•°æ®
        frame_data = radar_df[radar_df['frame'] == frame_idx]
        
        if len(frame_data) == 0:
            continue
        
        # è¿‡æ»¤ä½åŠŸç‡ç‚¹
        frame_data = frame_data[frame_data['mag'] >= args.min_power]
        
        if len(frame_data) == 0:
            continue
        
        # æå–é›·è¾¾æ•°æ®
        range_m = frame_data['range_m'].values
        az_deg = frame_data['az_deg'].values
        el_deg = frame_data['el_deg'].values
        power = frame_data['mag'].values
        
        # çƒåæ ‡è½¬ç¬›å¡å°”åæ ‡ï¼ˆé›·è¾¾åæ ‡ç³»ï¼‰
        radar_points_radar = radar_spherical_to_cartesian(range_m, az_deg, el_deg)
        
        # é›·è¾¾åæ ‡ç³»è½¬ç›¸æœºåæ ‡ç³»ï¼ˆå¸¦åˆšæ€§å˜æ¢ï¼‰
        radar_points_cam = transform_radar_to_camera_with_calibration(
            radar_points_radar,
            translation_offset=translation_offset
        )
        
        # æŠ•å½±åˆ°æ¯ä¸ªè§†è§’
        for cam_name in args.cameras:
            images_sorted, name_map = cam_images.get(cam_name, ([], {}))
            frame_name = f"{frame_idx:06d}"
            img_path, match_mode = choose_image(frame_name, order_idx, images_sorted, name_map)
            
            if img_path is None:
                continue
            
            image = cv2.imread(img_path)
            if image is None:
                continue
            
            # è·å–ç›¸æœºå‚æ•°
            K = cameras[cam_name]['K']
            R = cameras[cam_name]['R']
            T = cameras[cam_name]['T']
            dist = cameras[cam_name]['dist']
            
            # æŠ•å½±ç‚¹äº‘
            points_2d, depth = project_points(radar_points_cam, K, R, T, dist)
            
            # è¿‡æ»¤ï¼šæ·±åº¦ä¸ºæ­£ã€ä¸è¶…è¿‡æœ€å¤§æ·±åº¦ã€åœ¨å›¾åƒèŒƒå›´å†…
            h, w = image.shape[:2]
            valid_mask = (
                (depth > 0) &
                (depth <= args.max_depth) &
                (points_2d[:, 0] >= 0) & (points_2d[:, 0] < w) &
                (points_2d[:, 1] >= 0) & (points_2d[:, 1] < h)
            )
            
            points_2d_valid = points_2d[valid_mask]
            depth_valid = depth[valid_mask]
            power_valid = power[valid_mask]
            
            # ç»˜åˆ¶ç‚¹äº‘
            result = draw_pointcloud(
                image, points_2d_valid, depth_valid, power_valid,
                color_mode=args.color_mode,
                point_size=args.point_size
            )
            
            # æ·»åŠ æ ‡ç­¾
            cv2.putText(result, f'Frame: {frame_name}', (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            cv2.putText(result, f'View: {cam_name} | Points: {len(points_2d_valid)} (Aligned)', (10, 70), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            
            # ä¿å­˜ç»“æœ
            output_path = os.path.join(vis_output_dir, cam_name, f'{frame_name}.jpg')
            cv2.imwrite(output_path, result)
    
    print(f"\nâœ… å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {vis_output_dir}")
    print(f"   å¸§èŒƒå›´: {args.frame_start} - {args.frame_end}")
    print(f"   è§†è§’æ•°: {len(args.cameras)}")
    
    # ç”Ÿæˆè§†é¢‘
    if args.create_video:
        print(f"\nğŸ¬ å¼€å§‹ç”Ÿæˆè§†é¢‘ (fps={args.video_fps})...")
        video_dir = os.path.join(vis_output_dir, 'videos')
        os.makedirs(video_dir, exist_ok=True)
        
        for cam_name in args.cameras:
            cam_img_dir = os.path.join(vis_output_dir, cam_name)
            video_path = os.path.join(video_dir, f'{cam_name}.mp4')
            create_video_from_images(cam_img_dir, video_path, args.video_fps)
        
        print(f"\nâœ… è§†é¢‘ç”Ÿæˆå®Œæˆï¼ä¿å­˜åœ¨: {video_dir}")


if __name__ == '__main__':
    main()

