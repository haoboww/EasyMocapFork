#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°†SMPLç»“æœæŠ•å½±ä¸ºmaskåˆ°æ‰€æœ‰è§†è§’çš„RGBå›¾åƒä¸­
æ”¯æŒç”Ÿæˆè§†é¢‘è¾“å‡º
"""

import os
import sys
import argparse

# æ·»åŠ EasyMocapè·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

import cv2
import json
import numpy as np
import torch
from tqdm import tqdm
from glob import glob


def load_cameras(intri_path, extri_path, camera_names):
    """åŠ è½½ç›¸æœºå†…å¤–å‚"""
    cameras = {}
    
    # ä½¿ç”¨OpenCVè¯»å–YAMLï¼ˆæ”¯æŒOpenCVç‰¹å®šæ ¼å¼ï¼‰
    intri_fs = cv2.FileStorage(intri_path, cv2.FILE_STORAGE_READ)
    extri_fs = cv2.FileStorage(extri_path, cv2.FILE_STORAGE_READ)
    
    for cam_name in camera_names:
        cameras[cam_name] = {
            'K': intri_fs.getNode(f'K_{cam_name}').mat(),
            'dist': intri_fs.getNode(f'dist_{cam_name}').mat().flatten(),
            'R': extri_fs.getNode(f'Rot_{cam_name}').mat(),
            'T': extri_fs.getNode(f'T_{cam_name}').mat()
        }
    
    intri_fs.release()
    extri_fs.release()
    
    return cameras


def load_smpl_model(model_path):
    """åŠ è½½SMPLæ¨¡å‹"""
    from easymocap.bodymodel.smpl import SMPLModel
    
    device = torch.device('cpu')
    smpl = SMPLModel(
        model_path=model_path,
        model_type='smpl',
        device=device,
        NUM_SHAPES=10
    )
    return smpl


def project_points(points_3d, K, R, T, dist):
    """
    å°†3Dç‚¹æŠ•å½±åˆ°2Då›¾åƒå¹³é¢
    points_3d: (N, 3) - 3Dç‚¹
    K: (3, 3) - å†…å‚çŸ©é˜µ
    R: (3, 3) - æ—‹è½¬çŸ©é˜µ
    T: (3, 1) - å¹³ç§»å‘é‡
    dist: (5,) - ç•¸å˜ç³»æ•°
    """
    # è½¬æ¢åˆ°ç›¸æœºåæ ‡ç³»
    points_cam = (R @ points_3d.T + T).T
    
    # æŠ•å½±åˆ°å›¾åƒå¹³é¢
    points_2d = points_cam[:, :2] / points_cam[:, 2:3]
    
    # åº”ç”¨å†…å‚
    fx, fy = K[0, 0], K[1, 1]
    cx, cy = K[0, 2], K[1, 2]
    
    points_2d[:, 0] = points_2d[:, 0] * fx + cx
    points_2d[:, 1] = points_2d[:, 1] * fy + cy
    
    return points_2d, points_cam[:, 2]


def render_smpl_mask(img_shape, vertices, faces, K, R, T, dist):
    """
    æ¸²æŸ“SMPLæ¨¡å‹ä¸ºmask
    è¿”å›: äºŒå€¼mask (0/255)
    """
    h, w = img_shape[:2]
    
    # æŠ•å½±é¡¶ç‚¹
    points_2d, depth = project_points(vertices, K, R, T, dist)
    
    # åˆ›å»ºmask
    mask = np.zeros((h, w), dtype=np.uint8)
    
    # æŒ‰æ·±åº¦æ’åºé¢ç‰‡ï¼ˆä»è¿œåˆ°è¿‘ï¼‰
    face_depths = []
    for face in faces:
        avg_depth = np.mean([depth[face[0]], depth[face[1]], depth[face[2]]])
        face_depths.append(avg_depth)
    
    sorted_indices = np.argsort(face_depths)[::-1]
    
    # ç»˜åˆ¶é¢ç‰‡åˆ°mask
    for idx in sorted_indices:
        face = faces[idx]
        # åªç»˜åˆ¶æ·±åº¦ä¸ºæ­£çš„é¢ç‰‡
        if depth[face[0]] > 0 and depth[face[1]] > 0 and depth[face[2]] > 0:
            pts = points_2d[face].astype(np.int32)
            
            # æ£€æŸ¥æ˜¯å¦åœ¨å›¾åƒèŒƒå›´å†…
            if np.all((pts[:, 0] >= 0) & (pts[:, 0] < w) & 
                     (pts[:, 1] >= 0) & (pts[:, 1] < h)):
                cv2.fillConvexPoly(mask, pts, 255)
    
    return mask


def apply_mask_to_image(img, mask, mask_color=(0, 255, 0), alpha=0.5, mode='overlay'):
    """
    å°†maskåº”ç”¨åˆ°å›¾åƒä¸Š
    mode: 'overlay' - åŠé€æ˜å åŠ , 'binary' - äºŒå€¼mask, 'colored' - å½©è‰²mask, 'contour' - è½®å»“
    """
    if mode == 'binary':
        # è¿”å›äºŒå€¼maskï¼ˆ3é€šé“ï¼‰
        return cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
    
    elif mode == 'overlay':
        # åŠé€æ˜å åŠ 
        overlay = img.copy()
        mask_3ch = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
        overlay[mask > 0] = mask_color
        result = cv2.addWeighted(img, 1-alpha, overlay, alpha, 0)
        return result
    
    elif mode == 'colored':
        # å½©è‰²maskï¼Œä¿ç•™åŸå›¾èƒŒæ™¯
        result = img.copy()
        result[mask > 0] = mask_color
        return result
    
    elif mode == 'contour':
        # åªç»˜åˆ¶è½®å»“
        result = img.copy()
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(result, contours, -1, mask_color, 2)
        return result
    
    else:
        raise ValueError(f"Unknown mode: {mode}")


def collect_smpl_frames(output_root, frame_start, frame_end):
    """è·å–SMPLå¸§åˆ—è¡¨ï¼Œå…è®¸æ ¹æ®èµ·æ­¢å¸§è£å‰ªã€‚"""
    smpl_dir = os.path.join(output_root, 'smpl')
    smpl_files = sorted(glob(os.path.join(smpl_dir, '*.json')))
    frames = []
    for path in smpl_files:
        base = os.path.splitext(os.path.basename(path))[0]
        # å°è¯•æŒ‰æ•°å­—å¸§å·è¿‡æ»¤ï¼›éæ•°å­—åˆ™ç›´æ¥ä¿ç•™
        try:
            idx = int(base)
        except ValueError:
            idx = None
        if idx is not None:
            if idx < frame_start or idx > frame_end:
                continue
        frames.append((base, path))
    return frames


def load_camera_images(data_root, cam_name):
    """åŠ è½½æŸä¸ªç›¸æœºçš„æ‰€æœ‰jpgå›¾ç‰‡ï¼Œå¹¶è¿”å›æ’åºåˆ—è¡¨ä¸åŸºåç´¢å¼•ã€‚"""
    cam_dir = os.path.join(data_root, 'images', cam_name)
    if not os.path.isdir(cam_dir):
        return [], {}
    images = [
        os.path.join(cam_dir, f)
        for f in sorted(os.listdir(cam_dir))
        if f.lower().endswith('.jpg')
    ]
    name_map = {os.path.splitext(os.path.basename(p))[0]: p for p in images}
    return images, name_map


def choose_image(frame_name, order_idx, images_sorted, name_map):
    """
    é€‰æ‹©ä¸SMPLå¸§å¯¹åº”çš„å›¾åƒï¼š
    1) ä¼˜å…ˆåŸºåç²¾ç¡®åŒ¹é… (e.g., 000001)
    2) è‹¥æ— ï¼Œåˆ™å°è¯•åŸºååç¼€åŒ¹é… (å¤„ç†æŸäº›å‰ç¼€)
    3) å†æ— ï¼Œåˆ™æŒ‰æ’åºé¡ºåºå›é€€ (camX_at_timestamp)
    """
    if frame_name in name_map:
        return name_map[frame_name], "name"
    for name, path in name_map.items():
        if name.endswith(frame_name):
            return path, "suffix"
    if order_idx < len(images_sorted):
        return images_sorted[order_idx], "order"
    return None, "missing"


def create_video_from_images(image_dir, output_video_path, fps=30):
    """ä»å›¾åƒåºåˆ—åˆ›å»ºè§†é¢‘"""
    # è·å–æ‰€æœ‰å›¾åƒ
    images = sorted([f for f in os.listdir(image_dir) if f.lower().endswith('.jpg')])
    
    if len(images) == 0:
        print(f"   âš ï¸  {image_dir} ä¸­æ²¡æœ‰å›¾åƒï¼Œè·³è¿‡è§†é¢‘ç”Ÿæˆ")
        return False
    
    # è¯»å–ç¬¬ä¸€å¼ å›¾åƒè·å–å°ºå¯¸
    first_img = cv2.imread(os.path.join(image_dir, images[0]))
    if first_img is None:
        print(f"   âš ï¸  æ— æ³•è¯»å–å›¾åƒï¼Œè·³è¿‡è§†é¢‘ç”Ÿæˆ")
        return False
    
    h, w = first_img.shape[:2]
    
    # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (w, h))
    
    # å†™å…¥æ‰€æœ‰å¸§
    for img_name in tqdm(images, desc=f"ç”Ÿæˆè§†é¢‘ {os.path.basename(output_video_path)}", leave=False):
        img = cv2.imread(os.path.join(image_dir, img_name))
        if img is not None:
            out.write(img)
    
    out.release()
    print(f"   âœ… è§†é¢‘å·²ä¿å­˜: {output_video_path}")
    return True


def main():
    parser = argparse.ArgumentParser(description='å°†SMPLæŠ•å½±ä¸ºmaskåˆ°å¤šè§†è§’å›¾åƒ')
    parser.add_argument('--data_root', type=str, default='../data/examples/my_multiview',
                        help='æ•°æ®æ ¹ç›®å½•ï¼ˆåŒ…å«imagesã€intri.ymlã€extri.ymlï¼‰')
    parser.add_argument('--output_root', type=str, default='../output/detect_triangulate_fitSMPL',
                        help='è¾“å‡ºæ ¹ç›®å½•ï¼ˆåŒ…å«smplæ–‡ä»¶å¤¹ï¼‰')
    parser.add_argument('--smpl_model_path', type=str, default='../data/models/smpl/SMPL_NEUTRAL.pkl',
                        help='SMPLæ¨¡å‹è·¯å¾„')
    parser.add_argument('--cameras', type=str, nargs='+', 
                        default=['cam0', 'cam2', 'cam4', 'cam6', 'cam12'],
                        help='ç›¸æœºåç§°åˆ—è¡¨')
    parser.add_argument('--frame_start', type=int, default=0,
                        help='èµ·å§‹å¸§')
    parser.add_argument('--frame_end', type=int, default=99999,
                        help='ç»“æŸå¸§')
    parser.add_argument('--mask_mode', type=str, default='overlay',
                        choices=['overlay', 'binary', 'colored', 'contour'],
                        help='Maskæ¨¡å¼: overlay-åŠé€æ˜å åŠ , binary-äºŒå€¼mask, colored-å½©è‰²mask, contour-è½®å»“')
    parser.add_argument('--mask_color', type=int, nargs=3, default=[0, 255, 0],
                        help='Maské¢œè‰² (B G R)')
    parser.add_argument('--alpha', type=float, default=0.5,
                        help='overlayæ¨¡å¼çš„é€æ˜åº¦ (0-1)')
    parser.add_argument('--create_video', action='store_true',
                        help='æ˜¯å¦ç”Ÿæˆè§†é¢‘')
    parser.add_argument('--video_fps', type=int, default=10,
                        help='è§†é¢‘å¸§ç‡ï¼ˆå»ºè®®ä¸é‡‡é›†å¸§ç‡ä¸€è‡´ï¼Œé»˜è®¤10fpsï¼‰')
    parser.add_argument('--output_dir_name', type=str, default='vis_smpl_mask',
                        help='è¾“å‡ºç›®å½•åç§°')
    
    args = parser.parse_args()
    
    # é…ç½®å‚æ•°
    data_root = args.data_root
    output_root = args.output_root
    smpl_model_path = args.smpl_model_path
    camera_names = args.cameras
    frame_start = args.frame_start
    frame_end = args.frame_end
    mask_mode = args.mask_mode
    mask_color = tuple(args.mask_color)
    alpha = args.alpha
    create_video = args.create_video
    video_fps = args.video_fps
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    vis_output_dir = os.path.join(output_root, args.output_dir_name)
    os.makedirs(vis_output_dir, exist_ok=True)
    
    for cam_name in camera_names:
        os.makedirs(os.path.join(vis_output_dir, cam_name), exist_ok=True)
    
    # åŠ è½½ç›¸æœºå‚æ•°
    print("ğŸ“· åŠ è½½ç›¸æœºå‚æ•°...")
    intri_path = os.path.join(data_root, 'intri.yml')
    extri_path = os.path.join(data_root, 'extri.yml')
    cameras = load_cameras(intri_path, extri_path, camera_names)
    print(f"   æ‰¾åˆ° {len(cameras)} ä¸ªç›¸æœº: {camera_names}")
    
    # åŠ è½½SMPLæ¨¡å‹
    print("ğŸ“¦ åŠ è½½SMPLæ¨¡å‹...")
    smpl_model = load_smpl_model(smpl_model_path)
    print("   SMPLæ¨¡å‹åŠ è½½å®Œæˆ")
    
    # é¢„åŠ è½½æ¯ä¸ªç›¸æœºçš„å›¾ç‰‡åˆ—è¡¨
    cam_images = {cam: load_camera_images(data_root, cam) for cam in camera_names}
    for cam, (imgs, _) in cam_images.items():
        print(f"   ç›¸æœº {cam} å‘ç° {len(imgs)} å¼ å›¾ç‰‡")
    
    # å‡†å¤‡SMPLå¸§åˆ—è¡¨
    frames = collect_smpl_frames(output_root, frame_start, frame_end)
    if len(frames) == 0:
        print("âŒ æœªæ‰¾åˆ°SMPLå¸§ï¼Œè¯·æ£€æŸ¥è·¯å¾„ä¸èŒƒå›´è®¾ç½®")
        return
    
    print(f"\nğŸ­ å¼€å§‹ç”ŸæˆSMPL maskå¹¶æŠ•å½±åˆ°å›¾åƒ")
    print(f"   å¸§æ•°: {len(frames)}")
    print(f"   è§†è§’æ•°: {len(camera_names)}")
    print(f"   Maskæ¨¡å¼: {mask_mode}")
    print(f"   Maské¢œè‰²: {mask_color}")
    if mask_mode == 'overlay':
        print(f"   é€æ˜åº¦: {alpha}")
    print()
    
    for order_idx, (frame_name, smpl_path) in enumerate(tqdm(frames, desc="å¤„ç†è¿›åº¦")):
        # è¯»å–SMPLå‚æ•°
        with open(smpl_path, 'r') as f:
            smpl_data = json.load(f)
        if len(smpl_data) == 0:
            continue
        
        # æå–SMPLå‚æ•°ï¼ˆå‡è®¾åªæœ‰ä¸€ä¸ªäººï¼‰
        person_data = smpl_data[0]
        
        # å‡†å¤‡SMPLå‚æ•°
        poses = torch.FloatTensor(person_data['poses']).reshape(1, -1)
        shapes = torch.FloatTensor(person_data['shapes']).reshape(1, -1)
        Rh = torch.FloatTensor(person_data['Rh']).reshape(1, 3)
        Th = torch.FloatTensor(person_data['Th']).reshape(1, 3)
        
        # å‰å‘ä¼ æ’­è·å–é¡¶ç‚¹
        with torch.no_grad():
            params_dict = {
                'poses': poses,
                'shapes': shapes,
                'Rh': Rh,
                'Th': Th
            }
            vertices = smpl_model.vertices(params_dict, return_tensor=True).cpu().numpy()[0]
        
        faces = smpl_model.faces
        
        # æŠ•å½±åˆ°æ¯ä¸ªè§†è§’
        for cam_name in camera_names:
            images_sorted, name_map = cam_images.get(cam_name, ([], {}))
            img_path, match_mode = choose_image(frame_name, order_idx, images_sorted, name_map)
            if img_path is None:
                continue
            
            image = cv2.imread(img_path)
            if image is None:
                continue
            
            # è·å–ç›¸æœºå‚æ•°
            K = cameras[cam_name]['K']
            R = cameras[cam_name]['R']
            T = cameras[cam_name]['T']
            dist = cameras[cam_name]['dist']
            
            # æ¸²æŸ“SMPL mask
            mask = render_smpl_mask(image.shape, vertices, faces, K, R, T, dist)
            
            # åº”ç”¨maskåˆ°å›¾åƒ
            result = apply_mask_to_image(image, mask, mask_color, alpha, mask_mode)
            
            # æ·»åŠ å¸§å·æ ‡ç­¾
            cv2.putText(result, f'Frame: {frame_name}', (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            cv2.putText(result, f'View: {cam_name} ({match_mode})', (10, 70), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            
            # ä¿å­˜ç»“æœ
            output_path = os.path.join(vis_output_dir, cam_name, f'{frame_name}.jpg')
            cv2.imwrite(output_path, result)
    
    print(f"\nâœ… å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {vis_output_dir}")
    print(f"   å¸§èŒƒå›´: {frame_start} - {frame_end}")
    print(f"   è§†è§’æ•°: {len(camera_names)}")
    
    # ç”Ÿæˆè§†é¢‘
    if create_video:
        print(f"\nğŸ¬ å¼€å§‹ç”Ÿæˆè§†é¢‘ (fps={video_fps})...")
        video_dir = os.path.join(vis_output_dir, 'videos')
        os.makedirs(video_dir, exist_ok=True)
        
        for cam_name in camera_names:
            cam_img_dir = os.path.join(vis_output_dir, cam_name)
            video_path = os.path.join(video_dir, f'{cam_name}.mp4')
            create_video_from_images(cam_img_dir, video_path, video_fps)
        
        print(f"\nâœ… è§†é¢‘ç”Ÿæˆå®Œæˆï¼ä¿å­˜åœ¨: {video_dir}")


if __name__ == '__main__':
    main()


