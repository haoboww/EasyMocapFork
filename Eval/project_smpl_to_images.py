#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°†SMPLç»“æœæŠ•å½±åˆ°æ‰€æœ‰è§†è§’çš„RGBå›¾åƒä¸­
"""

import os
import sys

# æ·»åŠ EasyMocapè·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

# ä¿®å¤chumpyå…¼å®¹æ€§é—®é¢˜ï¼ˆå¿…é¡»åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—ä¹‹å‰ï¼‰
# import fix_chumpy

import cv2
import json
import numpy as np
import torch
from tqdm import tqdm
from glob import glob

def load_cameras(intri_path, extri_path, camera_names):
    """åŠ è½½ç›¸æœºå†…å¤–å‚"""
    cameras = {}
    
    # ä½¿ç”¨OpenCVè¯»å–YAMLï¼ˆæ”¯æŒOpenCVç‰¹å®šæ ¼å¼ï¼‰
    intri_fs = cv2.FileStorage(intri_path, cv2.FILE_STORAGE_READ)
    extri_fs = cv2.FileStorage(extri_path, cv2.FILE_STORAGE_READ)
    
    for cam_name in camera_names:
        cameras[cam_name] = {
            'K': intri_fs.getNode(f'K_{cam_name}').mat(),
            'dist': intri_fs.getNode(f'dist_{cam_name}').mat().flatten(),
            'R': extri_fs.getNode(f'Rot_{cam_name}').mat(),
            'T': extri_fs.getNode(f'T_{cam_name}').mat()
        }
    
    intri_fs.release()
    extri_fs.release()
    
    return cameras


def load_smpl_model(model_path):
    """åŠ è½½SMPLæ¨¡å‹"""
    from easymocap.bodymodel.smpl import SMPLModel
    
    device = torch.device('cpu')
    smpl = SMPLModel(
        model_path=model_path,
        model_type='smpl',
        device=device,
        NUM_SHAPES=10
    )
    return smpl


def project_points(points_3d, K, R, T, dist):
    """
    å°†3Dç‚¹æŠ•å½±åˆ°2Då›¾åƒå¹³é¢
    points_3d: (N, 3) - 3Dç‚¹
    K: (3, 3) - å†…å‚çŸ©é˜µ
    R: (3, 3) - æ—‹è½¬çŸ©é˜µ
    T: (3, 1) - å¹³ç§»å‘é‡
    dist: (5,) - ç•¸å˜ç³»æ•°
    """
    # è½¬æ¢åˆ°ç›¸æœºåæ ‡ç³»
    points_cam = (R @ points_3d.T + T).T
    
    # æŠ•å½±åˆ°å›¾åƒå¹³é¢
    points_2d = points_cam[:, :2] / points_cam[:, 2:3]
    
    # åº”ç”¨å†…å‚
    fx, fy = K[0, 0], K[1, 1]
    cx, cy = K[0, 2], K[1, 2]
    
    points_2d[:, 0] = points_2d[:, 0] * fx + cx
    points_2d[:, 1] = points_2d[:, 1] * fy + cy
    
    return points_2d, points_cam[:, 2]


def draw_smpl_wireframe(img, vertices, faces, K, R, T, dist, color=(0, 255, 0), thickness=1):
    """åœ¨å›¾åƒä¸Šç»˜åˆ¶SMPLçº¿æ¡†"""
    # æŠ•å½±é¡¶ç‚¹
    points_2d, depth = project_points(vertices, K, R, T, dist)
    
    # åªç»˜åˆ¶æ­£é¢çš„é¡¶ç‚¹
    valid_mask = depth > 0
    
    # ç»˜åˆ¶è¾¹ç¼˜ï¼ˆé‡‡æ ·éƒ¨åˆ†è¾¹ä»¥é¿å…å¤ªå¯†é›†ï¼‰
    for face in faces[::10]:  # æ¯10ä¸ªé¢ç”»ä¸€ä¸ª
        pts = []
        valid = True
        for idx in face:
            if valid_mask[idx]:
                pt = points_2d[idx].astype(np.int32)
                if 0 <= pt[0] < img.shape[1] and 0 <= pt[1] < img.shape[0]:
                    pts.append(pt)
                else:
                    valid = False
                    break
            else:
                valid = False
                break
        
        if valid and len(pts) == 3:
            pts = np.array(pts, dtype=np.int32)
            cv2.polylines(img, [pts], True, color, thickness, cv2.LINE_AA)
    
    return img


def draw_smpl_mesh(img, vertices, faces, K, R, T, dist, color=(0, 255, 0), alpha=0.6):
    """åœ¨å›¾åƒä¸Šç»˜åˆ¶å¡«å……çš„SMPLç½‘æ ¼"""
    # æŠ•å½±é¡¶ç‚¹
    points_2d, depth = project_points(vertices, K, R, T, dist)
    
    h, w = img.shape[:2]
    overlay = img.copy()
    
    # æŒ‰æ·±åº¦æ’åºé¢ç‰‡ï¼ˆä»è¿œåˆ°è¿‘ï¼‰
    face_depths = []
    for face in faces:
        avg_depth = np.mean([depth[face[0]], depth[face[1]], depth[face[2]]])
        face_depths.append(avg_depth)
    
    sorted_indices = np.argsort(face_depths)[::-1]
    
    # ç»˜åˆ¶é¢ç‰‡
    for idx in sorted_indices:
        face = faces[idx]
        # åªç»˜åˆ¶æ·±åº¦ä¸ºæ­£çš„é¢ç‰‡
        if depth[face[0]] > 0 and depth[face[1]] > 0 and depth[face[2]] > 0:
            pts = points_2d[face].astype(np.int32)
            
            # æ£€æŸ¥æ˜¯å¦åœ¨å›¾åƒèŒƒå›´å†…
            if np.all((pts[:, 0] >= 0) & (pts[:, 0] < w) & 
                     (pts[:, 1] >= 0) & (pts[:, 1] < h)):
                cv2.fillConvexPoly(overlay, pts, color)
    
    # èåˆ
    result = cv2.addWeighted(img, 1-alpha, overlay, alpha, 0)
    
    return result


def collect_smpl_frames(output_root, frame_start, frame_end):
    """è·å–SMPLå¸§åˆ—è¡¨ï¼Œå…è®¸æ ¹æ®èµ·æ­¢å¸§è£å‰ªã€‚"""
    smpl_dir = os.path.join(output_root, 'smpl')
    smpl_files = sorted(glob(os.path.join(smpl_dir, '*.json')))
    frames = []
    for path in smpl_files:
        base = os.path.splitext(os.path.basename(path))[0]
        # å°è¯•æŒ‰æ•°å­—å¸§å·è¿‡æ»¤ï¼›éæ•°å­—åˆ™ç›´æ¥ä¿ç•™
        try:
            idx = int(base)
        except ValueError:
            idx = None
        if idx is not None:
            if idx < frame_start or idx > frame_end:
                continue
        frames.append((base, path))
    return frames


def load_camera_images(data_root, cam_name):
    """åŠ è½½æŸä¸ªç›¸æœºçš„æ‰€æœ‰jpgå›¾ç‰‡ï¼Œå¹¶è¿”å›æ’åºåˆ—è¡¨ä¸åŸºåç´¢å¼•ã€‚"""
    cam_dir = os.path.join(data_root, 'images', cam_name)
    if not os.path.isdir(cam_dir):
        return [], {}
    images = [
        os.path.join(cam_dir, f)
        for f in sorted(os.listdir(cam_dir))
        if f.lower().endswith('.jpg')
    ]
    name_map = {os.path.splitext(os.path.basename(p))[0]: p for p in images}
    return images, name_map


def choose_image(frame_name, order_idx, images_sorted, name_map):
    """
    é€‰æ‹©ä¸SMPLå¸§å¯¹åº”çš„å›¾åƒï¼š
    1) ä¼˜å…ˆåŸºåç²¾ç¡®åŒ¹é… (e.g., 000001)
    2) è‹¥æ— ï¼Œåˆ™å°è¯•åŸºååç¼€åŒ¹é… (å¤„ç†æŸäº›å‰ç¼€)
    3) å†æ— ï¼Œåˆ™æŒ‰æ’åºé¡ºåºå›é€€ (camX_at_timestamp)
    """
    if frame_name in name_map:
        return name_map[frame_name], "name"
    for name, path in name_map.items():
        if name.endswith(frame_name):
            return path, "suffix"
    if order_idx < len(images_sorted):
        return images_sorted[order_idx], "order"
    return None, "missing"


def main():
    # é…ç½®å‚æ•°
    data_root = '/home/bupt630/Dabai/AmmWave/EasyMocap/data/examples/my_multiview'
    output_root = '/home/bupt630/Dabai/AmmWave/EasyMocap/output/detect_triangulate_fitSMPL'
    smpl_model_path = '/home/bupt630/Dabai/AmmWave/EasyMocap/data/models/smpl/SMPL_NEUTRAL.pkl'
    
    # camera_names = ['01', '02', '03', '04', '05', '06', '07', '08']
    # camera_names = ['02', '04', '06', '08']
    # camera_names = ['01', '02', '03', '04', '05']
    camera_names = ['cam2', 'cam10', 'cam12', 'cam0']
    # camera_names = ['02','03','07','08']
    frame_start = 0
    frame_end = 99999  # æ”¯æŒæ›´å¤§èŒƒå›´ï¼Œå®é™…å¸§æ•°ç”±æ•°æ®å†³å®š
    # frame_start = 100
    # frame_end = 169  # åŒ…å«119
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    vis_output_dir = os.path.join(output_root, 'vis_smpl_projection')
    os.makedirs(vis_output_dir, exist_ok=True)
    
    for cam_name in camera_names:
        os.makedirs(os.path.join(vis_output_dir, cam_name), exist_ok=True)
    
    # åŠ è½½ç›¸æœºå‚æ•°
    print("ğŸ“· åŠ è½½ç›¸æœºå‚æ•°...")
    intri_path = os.path.join(data_root, 'intri.yml')
    extri_path = os.path.join(data_root, 'extri.yml')
    cameras = load_cameras(intri_path, extri_path, camera_names)
    print(f"   æ‰¾åˆ° {len(cameras)} ä¸ªç›¸æœº: {camera_names}")
    
    # åŠ è½½SMPLæ¨¡å‹
    print("ğŸ“¦ åŠ è½½SMPLæ¨¡å‹...")
    smpl_model = load_smpl_model(smpl_model_path)
    print("   SMPLæ¨¡å‹åŠ è½½å®Œæˆ")
    
    # é¢„åŠ è½½æ¯ä¸ªç›¸æœºçš„å›¾ç‰‡åˆ—è¡¨
    cam_images = {cam: load_camera_images(data_root, cam) for cam in camera_names}
    for cam, (imgs, _) in cam_images.items():
        print(f"   ç›¸æœº {cam} å‘ç° {len(imgs)} å¼ å›¾ç‰‡")
    
    # å‡†å¤‡SMPLå¸§åˆ—è¡¨
    frames = collect_smpl_frames(output_root, frame_start, frame_end)
    if len(frames) == 0:
        print("âŒ æœªæ‰¾åˆ°SMPLå¸§ï¼Œè¯·æ£€æŸ¥è·¯å¾„ä¸èŒƒå›´è®¾ç½®")
        return
    print(f"ğŸ¨ å¼€å§‹æŠ•å½±SMPLåˆ°å›¾åƒï¼Œå…± {len(frames)} å¸§")
    
    for order_idx, (frame_name, smpl_path) in enumerate(tqdm(frames, desc="å¤„ç†è¿›åº¦")):
        # è¯»å–SMPLå‚æ•°
        with open(smpl_path, 'r') as f:
            smpl_data = json.load(f)
        if len(smpl_data) == 0:
            continue
        
        # æå–SMPLå‚æ•°ï¼ˆå‡è®¾åªæœ‰ä¸€ä¸ªäººï¼‰
        person_data = smpl_data[0]
        
        # å‡†å¤‡SMPLå‚æ•°
        poses = torch.FloatTensor(person_data['poses']).reshape(1, -1)
        shapes = torch.FloatTensor(person_data['shapes']).reshape(1, -1)
        Rh = torch.FloatTensor(person_data['Rh']).reshape(1, 3)
        Th = torch.FloatTensor(person_data['Th']).reshape(1, 3)
        
        # å‰å‘ä¼ æ’­è·å–é¡¶ç‚¹
        with torch.no_grad():
            params_dict = {
                'poses': poses,
                'shapes': shapes,
                'Rh': Rh,
                'Th': Th
            }
            vertices = smpl_model.vertices(params_dict, return_tensor=True).cpu().numpy()[0]
        
        faces = smpl_model.faces
        
        # æŠ•å½±åˆ°æ¯ä¸ªè§†è§’
        for cam_name in camera_names:
            images_sorted, name_map = cam_images.get(cam_name, ([], {}))
            img_path, match_mode = choose_image(frame_name, order_idx, images_sorted, name_map)
            if img_path is None:
                continue
            
            image = cv2.imread(img_path)
            if image is None:
                continue
            
            # è·å–ç›¸æœºå‚æ•°
            K = cameras[cam_name]['K']
            R = cameras[cam_name]['R']
            T = cameras[cam_name]['T']
            dist = cameras[cam_name]['dist']
            
            # ç»˜åˆ¶SMPLç½‘æ ¼ï¼ˆçº¿æ¡†æ¨¡å¼ï¼‰
            result = draw_smpl_wireframe(image, vertices, faces, K, R, T, dist, 
                                        color=(0, 255, 0), thickness=1)
            
            # ä¹Ÿå¯ä»¥ä½¿ç”¨å¡«å……æ¨¡å¼ï¼ˆå–æ¶ˆæ³¨é‡Šä¸‹é¢è¿™è¡Œå¹¶æ³¨é‡Šä¸Šé¢è¿™è¡Œï¼‰
            # result = draw_smpl_mesh(image, vertices, faces, K, R, T, dist, 
            #                        color=(0, 255, 0), alpha=0.6)
            
            # æ·»åŠ å¸§å·æ ‡ç­¾
            cv2.putText(result, f'Frame: {frame_name}', (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            cv2.putText(result, f'View: {cam_name} ({match_mode})', (10, 70), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            
            # ä¿å­˜ç»“æœ
            output_path = os.path.join(vis_output_dir, cam_name, f'{frame_name}.jpg')
            cv2.imwrite(output_path, result)
    
    print(f"\nâœ… å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {vis_output_dir}")
    print(f"   å¸§èŒƒå›´: {frame_start} - {frame_end}")
    print(f"   è§†è§’æ•°: {len(camera_names)}")


if __name__ == '__main__':
    main()

